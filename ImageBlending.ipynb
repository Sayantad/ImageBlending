{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b4282f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from IPython.display import display\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "34a9a691",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv2Show(img):\n",
    "    img=cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    display(Image.fromarray(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "18cbce89",
   "metadata": {},
   "outputs": [],
   "source": [
    "back_img = cv2.imread('airport.jpg')\n",
    "front_img = cv2.imread('bags.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "db118bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cv2Show(front_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "93632bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cv2Show(back_img)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69349c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "aeb2e69a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3762, 5636, 3)\n",
      "(452, 452, 3)\n"
     ]
    }
   ],
   "source": [
    "print(back_img.shape)\n",
    "print(front_img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b3097859",
   "metadata": {},
   "outputs": [],
   "source": [
    "front_small_img = cv2.resize(front_img,(452,452))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b7221ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cv2Show(front_small_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "883f0539",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_offset=2200\n",
    "y_offset=3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "461f9144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "452 452 3\n"
     ]
    }
   ],
   "source": [
    "rows,columns,chanels = front_small_img.shape\n",
    "print(rows,columns,chanels)\n",
    "roi = back_img[y_offset:3452, x_offset:2652]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "63e04340",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cv2Show(roi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9d8c8d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "front_small_img = cv2.GaussianBlur(front_small_img,(5,5),0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "71e6a054",
   "metadata": {},
   "outputs": [],
   "source": [
    "front_small_img_gray = cv2.cvtColor(front_small_img, cv2.COLOR_RGB2GRAY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3857d71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cv2Show(front_small_img_gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1435db55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ret, mask = cv2.threshold(front_small_img_gray, 125, 180, cv2.THRESH_BINARY)\n",
    "ret, mask = cv2.threshold(front_small_img_gray, 120, 255, cv2.THRESH_BINARY + \n",
    "                                            cv2.THRESH_OTSU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "eabd268a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cv2Show(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "3cbeb5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "bg = cv2.bitwise_or(roi,roi,mask = mask)\n",
    "#cv2Show(bg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "605b4189",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_inv = cv2.bitwise_not(front_small_img_gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e68d76cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cv2Show(mask_inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "bddba105",
   "metadata": {},
   "outputs": [],
   "source": [
    "fg = cv2.bitwise_and(front_small_img,front_small_img, mask=mask_inv)\n",
    "#cv2Show(fg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c15cbe81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SECTION B\n",
    "# functions for blending operations\n",
    "\n",
    "# takes a pixel from image 1 (pix_1)  and blends it with pixel from image 2 (pix_2)\n",
    "# depending on the value given in perc (percentage)\n",
    "# perc = 0 or 255 or [0,0,0] or [255,255,255] (equals 0 or 100 percent) -> will perform \n",
    "# no blending at all and return the value of image 1 or image 2;\n",
    "# by constrast, all values in between will give a weighted blend of the two images\n",
    "# can be used with scalars or numpy arrays (perc as well which is a greyscale image then)\n",
    "def mix_pixel(pix_1, pix_2, perc):\n",
    "\n",
    "    return (perc/255 * pix_1) + ((255 - perc)/255 * pix_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d8823f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for blending images depending on values given in mask\n",
    "def blend_images_using_mask(img_orig, img_for_overlay, img_mask):\n",
    "\n",
    "    # turn mask into 24 bit greycale image if necessary,\n",
    "    # because mix_pixel() requires numpy arrarys having the same dimensions;\n",
    "    # if img is 24-bit bgr, the image has three dimensions, if 8 bit grey only 2\n",
    "    if len(img_mask.shape) != 3:\n",
    "        img_mask = cv2.cvtColor(img_mask, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    # interpolate between two images (img_orig and img_to_insert)\n",
    "    # using the weights in img_mask (each pixel (0,0,0 to 255,255,255) \n",
    "    # serves as individual weight);\n",
    "    # because all three images are numpy arrays standard operators\n",
    "    # for multiplication etc. will be applied to all values in arrays\n",
    "    img_res = mix_pixel(img_orig, img_for_overlay, img_mask)\n",
    "\n",
    "    return img_res.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "abcdce69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SECTION C; blend images and display results\n",
    "# call function defined above -> blending with \"weighted\" mask\n",
    "img_blended = blend_images_using_mask(fg, bg,mask_inv)\n",
    "#img_blended = blend_images_using_mask(front_small_img, bg,mask_inv)\n",
    "\n",
    "#cv2Show(img_blended)\n",
    "cv2.imwrite('roi_blended.jpg',img_blended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "2823c106",
   "metadata": {},
   "outputs": [],
   "source": [
    "#final_roi = cv2.add(bg,fg)\n",
    "#cv2Show(final_roi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "341890bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#small_img = final_roi\n",
    "small_img = img_blended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "28595b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "back_img[y_offset : y_offset + small_img.shape[0], x_offset : x_offset + small_img.shape[1]]= small_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f904f425",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cv2Show(back_img)\n",
    "cv2.imwrite('output_blending.jpg',back_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63d4abf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f006ff2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c3cfe8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2769e33d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "eba3f44b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(452, 452, 3)\n"
     ]
    }
   ],
   "source": [
    "# SECTION A\n",
    "# use opencv function imread to load images\n",
    "\n",
    "# code only works with 24 bit images (but can be adapted)\n",
    "\n",
    "# load image that will serve as \"foreground\"\n",
    "img = cv2.imread(\"bags.jpg\",  cv2.IMREAD_UNCHANGED)\n",
    "print(img.shape)\n",
    "#img = np.rot90(img,3) # used to rotate image if necessary\n",
    "\n",
    "# load image that will be blended with foreground image\n",
    "img_insert = cv2.imread(\"airport.jpg\", cv2.IMREAD_UNCHANGED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "579a200b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load mask; mask defines where and to which extent the two images \n",
    "# above are blended together\n",
    "#1)\n",
    "# simple binary image (black and white only)\n",
    "#img_insert_mask = cv2.imread(\"SimpleMask.jpg\", cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "# or do additional blurring here by using e.g.\n",
    "#img_insert_mask = cv2.blur(img_insert_mask, (33,33))\n",
    "#or invert mask (turns black to white and vice versa)\n",
    "#img_insert_mask = cv2.bitwise_not(img_insert_mask)\n",
    "\n",
    "#2)\n",
    "# or use more sophisticated masks\n",
    "#img_insert_mask = cv2.imread(\"NotSoSimpleMask.jpg\", cv2.IMREAD_UNCHANGED)\n",
    "front_small_img_gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "front_small_img_gray=cv2.GaussianBlur(front_small_img_gray,(5,5),0)\n",
    "ret, mask = cv2.threshold(front_small_img_gray, 125, 255, cv2.THRESH_BINARY)\n",
    "mask_inv = cv2.bitwise_not(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "13a6b8c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=452x452 at 0x2623534AD30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#cv2Show(mask_inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "b63399dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#img_insert_mask = cv2.imread(\"TransitionMask.jpg\", cv2.IMREAD_UNCHANGED)# transition from black to white\n",
    "\n",
    "#3)\n",
    "# or modify the image mask by changing black values, for instance (are 0 or [0,0,0] in original mask image),\n",
    "# use the NumPy where() function for that, which takes a condition as first argument;\n",
    "# the second argument tells the function which value should be assigned if condition is met,\n",
    "# while the third argument tells the function which value will be assigned if condition is not met;\n",
    "# for three channel greyscale images (24 bit) use for instance\n",
    "#img_insert_mask = np.where(img_insert_mask[:,:] ==[0,0,0],img_insert_mask[:,:] + [170,170,170], img_insert_mask)\n",
    "# for  one channel greycale images (8 bit) use\n",
    "#img_insert_mask = np.where(img_insert_mask[:,:] ==0,img_insert_mask[:,:] + 170, img_insert_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b48df1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3243f21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c14b199",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f2c8c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb2ca86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfgpu",
   "language": "python",
   "name": "tfgpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
